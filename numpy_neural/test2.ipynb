{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from data.config import *\n",
    "from report.dumps import *\n",
    "from nn.model import model\n",
    "from nn.funcs import *\n",
    "from data.dataset import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ds, verbose=False, phase=\"Validation\"):\n",
    "    ds.reset()\n",
    "    hits = 0\n",
    "    mean_loss = 0\n",
    "    while not(ds.iter_done()):\n",
    "        x, y = ds.next()\n",
    "        o, batch_loss = nn.forward(x, y, train=False)\n",
    "        print(o)\n",
    "        hits += batch_hits(o, y)\n",
    "        mean_loss += np.mean(batch_loss)\n",
    "        #if verbose:\n",
    "        #    print(\"Loss: \" + str(mean_loss), \" Predicted: \" + str(o), \" Expected: \" + str(y))\n",
    "    accuracy = float(hits) / float(ds.size)\n",
    "    mean_loss = float(mean_loss) / float(ds.size)\n",
    "    if verbose:\n",
    "        print(phase + \" Accuracy: \" + str(accuracy) + \" Mean Loss \" + str(mean_loss))\n",
    "    return accuracy, mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nn, hp, val_hist, train_hist, logger):\n",
    "    cur_epoch = 1\n",
    "    cur_iter = 1\n",
    "    for i in range(1, hp.epochs+1):\n",
    "        train_loss = 0\n",
    "        hits = 0\n",
    "        cur_trained = 0\n",
    "        while not(hp.ds_train.iter_done()):\n",
    "            x, y = hp.ds_train.next()\n",
    "            #print(y)\n",
    "            o, batch_loss = nn.forward(x, y)\n",
    "            nn.backward(y, o)\n",
    "            nn.update(hp.lr)\n",
    "\n",
    "            hits += batch_hits(o, y)\n",
    "            cur_trained += len(x)\n",
    "            train_loss += np.mean(batch_loss)\n",
    "\n",
    "            if cur_iter % hp.validate_every_no_of_batches == 0:\n",
    "                train_accuracy = float(hits) / float(cur_trained)\n",
    "                train_loss = float(train_loss) / float(cur_trained)\n",
    "                train_hist.add(cur_iter, train_loss, train_accuracy)\n",
    "                logger.write((cur_epoch, \"Training\", cur_iter, train_accuracy, train_loss))\n",
    "                hits = 0\n",
    "                train_loss = 0\n",
    "\n",
    "                if hp.ds_val is not None:\n",
    "                    val_accuracy, val_loss = test(hp.ds_val, True)\n",
    "                    val_hist.add(cur_iter, val_loss, val_accuracy)\n",
    "                    logger.write((cur_epoch, \"Val\", cur_iter, val_accuracy, val_loss))\n",
    "            cur_iter += 1\n",
    "        cur_epoch += 1\n",
    "        hp.ds_train.reset()\n",
    "    return val_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((72, 4), (72,)) ((18, 4), (18,)) ((60, 4), (60,))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m logger \u001b[39m=\u001b[39m nnlogger(hp\u001b[39m.\u001b[39moutput_log, (\u001b[39m\"\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPhase\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mIteration\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# Train the model using the provided train function\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m train(nn, hp, val_hist, train_hist, logger)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# Wrapper for making predictions without calculating loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(nn, X):\n",
      "\u001b[1;32m/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m hits \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m val_accuracy, val_loss \u001b[39m=\u001b[39m test(hp\u001b[39m.\u001b[39;49mds_val, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m val_hist\u001b[39m.\u001b[39madd(cur_iter, val_loss, val_accuracy)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m logger\u001b[39m.\u001b[39mwrite( (cur_epoch, \u001b[39m\"\u001b[39m\u001b[39mVal\u001b[39m\u001b[39m\"\u001b[39m, cur_iter, val_accuracy, val_loss) )\n",
      "\u001b[1;32m/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest\u001b[39m(ds, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, phase\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValidation\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     ds\u001b[39m.\u001b[39;49mreset()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     hits \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniellizano/Documents/numpy_neural_net/numpy_neural/test2.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     mean_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reset'"
     ]
    }
   ],
   "source": [
    "# Load the IRIS dataset\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 0].reshape(-1, 1)  # Sepal Length as feature\n",
    "y = iris.data[:, 2].reshape(-1, 1)  # Petal Length as target\n",
    "\n",
    "# Standardize the dataset\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the provided dataset class\n",
    "batch_size = 10\n",
    "train_dataset = dataset(X_train, y_train, batch_size)\n",
    "test_dataset = dataset(X_test, y_test, batch_size)\n",
    "\n",
    "# Load hyperparameters for the IRIS dataset\n",
    "hp = hyperparams(ConfigEnum.IRIS)\n",
    "hp.input_size = 1  # One feature (Sepal Length)\n",
    "hp.output_size = 1  # One target (Petal Length)\n",
    "hp.batch_size = batch_size\n",
    "hp.ds_train = train_dataset\n",
    "hp.ds_val = None  # No validation set for simplicity\n",
    "hp.ds_test = test_dataset\n",
    "hp.validate_every_no_of_batches = 10\n",
    "hp.epochs = 100\n",
    "hp.lr = 0.01\n",
    "hp.has_dropout = False\n",
    "hp.hidden_shapes = [10]  # Define some hidden layers if needed\n",
    "\n",
    "# MSE Loss and Gradient Functions\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean(np.square(y_true - y_pred))\n",
    "\n",
    "def mse_loss_grad(y_true, y_pred):\n",
    "    return -2 * (y_true - y_pred) / y_true.size\n",
    "\n",
    "# Initialize the model\n",
    "nn = model(hp.input_size, hp.output_size, hp.hidden_shapes, tanh, tanh_grad, has_dropout=hp.has_dropout, dropout_perc=hp.dropout_perc)\n",
    "nn.output_activation = lambda x: x  # Identity function\n",
    "nn.output_activation_grad = lambda x: 1  # Derivative of identity is 1\n",
    "nn.loss = mse_loss\n",
    "nn.loss_grad = mse_loss_grad\n",
    "\n",
    "# Historians and logger\n",
    "val_hist = historian()\n",
    "train_hist = historian()\n",
    "logger = nnlogger(hp.output_log, (\"Epoch\", \"Phase\", \"Iteration\", \"Loss\"))\n",
    "\n",
    "# Train the model using the provided train function\n",
    "train(nn, hp, val_hist, train_hist, logger)\n",
    "\n",
    "# Wrapper for making predictions without calculating loss\n",
    "def predict(nn, X):\n",
    "    outputs = []\n",
    "    for x in X:\n",
    "        data = x\n",
    "        for layer in nn.hidden_layers:\n",
    "            data = layer.forward(data)\n",
    "        o = nn.loss_layer.forward(data)\n",
    "        outputs.append(o)\n",
    "    return np.array(outputs).flatten()\n",
    "\n",
    "# Test the model using the provided test function and calculate MSE\n",
    "def test_model(nn, X_test, y_test):\n",
    "    y_pred = predict(nn, X_test)\n",
    "    mse = mse_loss(y_test, y_pred)\n",
    "    print(f\"Test MSE: {mse}\")\n",
    "    return y_pred\n",
    "\n",
    "# Test the model\n",
    "y_test_pred = test_model(nn, X_test, y_test)\n",
    "\n",
    "# Plot results\n",
    "nnplotter.view(val_hist, train_hist)\n",
    "\n",
    "# Close logger\n",
    "logger.close()\n",
    "\n",
    "# Function to plot the linear regression line\n",
    "def plot_regression_line(nn, X_train, y_train, X_test, y_test, y_test_pred):\n",
    "    # Predict outputs for train sets\n",
    "    y_train_pred = predict(nn, X_train)\n",
    "    \n",
    "    # Plot training data and regression line\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X_train, y_train, color='blue', label='Training Data')\n",
    "    plt.scatter(X_test, y_test, color='green', label='Test Data')\n",
    "    plt.plot(X_train, y_train_pred, color='red', label='Regression Line (Train)')\n",
    "    plt.plot(X_test, y_test_pred, color='orange', label='Regression Line (Test)')\n",
    "    plt.xlabel('Sepal Length (standardized)')\n",
    "    plt.ylabel('Petal Length (standardized)')\n",
    "    plt.title('Linear Regression on Sepal Length vs Petal Length (IRIS Dataset)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Extract training and test data from the dataset class instances\n",
    "X_train = train_dataset.compl_x\n",
    "y_train = train_dataset.compl_y\n",
    "X_test = test_dataset.compl_x\n",
    "y_test = test_dataset.compl_y\n",
    "\n",
    "# Plot the regression line\n",
    "plot_regression_line(nn, X_train, y_train, X_test, y_test, y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
